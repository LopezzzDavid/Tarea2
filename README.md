<H1 align = "center"> Tarea 2 - ARQUITECTURAS DE COMPUTACI√ìN </H1>

<P align = "center">
  <strong> David Santiago L√≥pez Maldonado </strong></P>
 <P align = "center">
   <strong> Sistemas Digitales III </strong></P>
 <P align = "center">
   <strong> 15.08.2025 </strong></P>


   <img src="https://media1.giphy.com/media/v1.Y2lkPTc5MGI3NjExb2ZmZmR3Zm5jZmJ0MzBpODEwbW4wM3ltZHBuaWV6YWY2YTluMm1oeSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/fdOA43sHFE6Pu/giphy.gif" width="1010"/>
</div>

## Introducci√≥n
  <P align = "justify">
    Por medio del siguiente documento se muestran diversas arquitecturas de computaci√≥n que presentan un cambio importante frente a la computaci√≥n cl√°sica que aborda mayormente una arquitectura Von Neumann. Teniendo cinco (5) tipos de aarquitectura diferentes como lo son <strong> Computaci√≥n cu√°ntica </strong>, <strong> Computador neurom√≥rfico </strong>, <strong> Ordenador biol√≥gico </strong>, <strong> Computaci√≥n Heterog√©nea </strong> y <strong> Computaci√≥n de borde </strong>.
  
  Cada uno de estos modelos presenta fundamentos, arquitecturas y aplicaciones diferentes, pero todos comparten el objetivo com√∫n de <em>mejorar el rendimiento, la eficiencia y la capacidad de procesamiento de la informaci√≥n</em> frente a los desaf√≠os actuales de la tecnolog√≠a. Asimismo, se explorar√°n sus ventajas, desventajas, principales hitos hist√≥ricos y el estado actual de desarrollo, con el fin de comprender su potencial y limitaciones.
  
  </P>

## 1. Computaci√≥n cu√°ntica üíª‚öõÔ∏è
<p align = "justify">
  La computaci√≥n cu√°ntica aplica los conceptos f√≠sicos y matem√°ticos de la mec√°nica cu√°ntica a la inform√°tica para poder procesar informaci√≥n de una forma mucho m√°s r√°pida y eficiente que la computaci√≥n cl√°sica.<br/>
  
  En lugar de trabajar con **bits** que solo representan un estado o un nivel (_0 o 1_), la computaci√≥n cu√°ntica emplea **qubits**, es decir, bits cu√°nticos que gracias al estado de superposici√≥n pueden representar ambos estados o niveles (_0 y 1_) al mismo tiempo. Esta propiedad junto con algunas otras, permiten explorar y calcular varias soluciones o respuestas paralelamente. Todo esto como alternativa a problemas que los computadores tradicionales o supercomputadores no pueden resolver o tardan demasiado tiempo en resolverlos [2][3].

-![Computadora cu√°ntica IBM](https://github.com/user-attachments/assets/b1b908d9-f8bb-4899-a17b-ff1778e21e5e)

  
  </p>
  
  - ### Arquitectura de un computador cu√°ntico
    - ### Unidad de Procesamiento Cu√°ntico (QPU):
      <p align = "justify">
        Esta unidad de procesamiento cu√°ntico es an√°loga a la CPU de un computador tradicional, sin embargo, como se explic√≥ antes, no se procesan bits comunes sino bits cu√°nticos (qubits) los cuales funcionan mediante fen√≥menos cu√°nticos como la <i> superposici√≥n </i> y el <i> entrelazamiento </i>. Estos procesadores son los encargados de realizar las operaciones cu√°nticas que se definieron mediante algoritmos cu√°nticos, incluyendo las compuertas cu√°nticas, que son las que alteran los estados de los qubits. Es tambi√©n conocido como el coraz√≥n de la computadora, alberga los qubits y controla las operaciones que la m√°quina har√°. <br/>
        <img width="1515" height="852" alt="QPU NVIDIA" src="https://github.com/user-attachments/assets/0895196c-638b-49bf-a43c-d82b589ea64b" />
  
        Los componentes de las QPU son los siguientes:     
      </p>
      <ul>
        <li>
          <strong> <ins> Qubits  </ins> </strong>: Son las unidades fundamentales de la computaci√≥n cu√°ntica. Son capaces de representar dos estados simult√°neamente (0 y 1) mediante el fen√≥meno de superposici√≥n. <br/>
          Los qubits se pueden crear mediante tecnolog√≠as como: <br/>
          <ul>
            <li>
              <strong> <i> circuitos superconductores </i> </strong>: Son circuitos fabricados con materiales superconductores que est√°n enfriados con una temperatura cercana al cero absoluto <strong> (0¬∞ k = -273.15¬∞ C = -459.63¬∞ F). </strong> <br/>
            </li>
            <li>
               <strong> <i> Iones atrapados </i> </strong>: Son √°tomos cargados suspendidos en trampas electroagn√©ticas. <br/>
            </li>
            <li>
               <strong> <i> Fotones </i> </strong>: Aprovechan par√≠culas de luz para procesar informaci√≥n.<br/>
            </li>
            <li>
               <strong> <i> Puntos cu√°nticos </i> </strong>: Son nanoestructuras que aislan electrones. <br/>
            </li>
            <li>
               <strong> <i> Qubits de Esp√≠n </i> </strong>: Dependen del esp√≠n de los electrones o n√∫cleos. <br/>
            </li>
          </ul>
          <li>
            <strong> <ins> Compuertas cu√°nticas </ins> </strong>: An√°logas a las compuertas l√≥gicas, las compuertas cu√°nticas manipulan qubits de formas controladas para poder realizar c√°lculos complejos y resolver problemas que ser√≠an imposibles de resolver con computadores convencionales.
          </li>
        <li>
          <strong> <ins> Interconexiones </ins> </strong>: Permiten la comunicaci√≥n entre qubits y dem√°s QPU para poder escalar los computadores cu√°nticos y realizar c√°lculos m√°s complejos
        </li>
        </li>
      </ul>
       
    - ### Electr√≥nica de control:
      <p align = "justify">
        Gestiona las operaciones del computador cu√°ntico, genera y env√≠a se√±ales precisas (microondas, radiofrecuencia o l√°ser) que manipulan los qubits y las compuertas cu√°nticas en la QPU, adem√°s sincronizan las operaciones para que  los resultados precisos sean garantizados. 
      </p>

    - ### Infraestructura de refrigeraci√≥n:
       <p align = "justify">
          Para garantizar la coherencia de los qubits y minimizar el ruido t√©rmico, es necesario que el computador se mantenga a temperaturas cercanas al cero absoluto. Este sistema est√° alimentado por refrigeradores de diluci√≥n que mantienen el hardware a temperaturas de unos 10mK-20mK y permiten el aislamiento del procesador al calor y al ruido. Estos refrigeradores funcionan mediante la mezcla de is√≥tpos de Helio. Los aisladores criog√©nicos protegen la QPU de interferencias t√©rmicas y del ruido externo. Los amplificadores criog√©nicos amplifican las se√±ales d√©biles emitidas por los qubits para medirlas con precisi√≥n sin agregar ruido adicional.
        </p>

     - ### Infraestructura de correcci√≥n de errores cu√°nticos:
        <p align = "justify">
          Conocida como QEC (Quantum Error Correction), esta infraestructura se encarga de darle fiabilidad a los qubits, estos son demasiado sensibles a interferencias ambientales y a imperfecciones de la m√°quina. Los estados cu√°nticos de los qubits pueden degradarse r√°pidamente y esto conlleva a errores computacionales y entre mayor escalabilidad, mayor probabilidad de error, de ah√≠ la justificaci√≥n de esta infraestructura. <br/>
          Para evitar la alteraci√≥n en los estados cu√°nticos de los qubits, los qubits l√≥gicos se codifican en diferentes qubits fisicos, permitiendo la detecci√≥n de errores. Los circuitos especializados detectan la ubicaci√≥n de los errores y se aplica la correcci√≥n correspondiente como, por ejemplo, invertir los qubits para poder restaurar el qubit l√≥gico.
        </p>
      - ### Interfaz de computaci√≥n cl√°sica:
        <p align = "justify">
          Esta interfaz de computaci√≥n cl√°sica controla el flujo de operaciones de la computadora cu√°ntica, sirve como un puente entre lo convencional y lo cu√°ntico. Es capaz de gestionar la entrada y salida de los c√°lculos cu√°nticos, asiste en las tareas como los c√°lculos de correcci√≥n de errores e interpreta los resultados de las medici√≥nes obtenidas.
        </p>
      - ### Interconexiones cu√°nticas:
        <p>
          Permiten las comunicaciones cu√°nticas y las redes cu√°nticas, son las responsables de transmitir informaci√≥n cu√°ntica entre computadoras cu√°nticas. Son imporantes para la escalabilidad de estas computadoras y para permitir el procesamiento cu√°ntico colaborativo en diferentes sistemas.
        </p>
 
  - ### Historia
    <p align = "justify">
      <ul>
        <li>
          <strong> 1900 - 1930 </strong> <br/>
          <ul>
            <li>
              <p align = "justify">
            <strong> <i> 1900 </i> </strong> ‚û°Ô∏è Max Planck descubri√≥ que la energ√≠a es emitida y absorbida por paquetes discretos llamados "quanta", esto solucion√≥ el problema de radiaci√≥n de cuerpo negro que los f√≠sicos a√∫n no pod√≠an entender. Adem√°s, desafi√≥ la fisica cl√°sica al introducir la discresi√≥n a escala at√≥mica, dando como origen la teor√≠a cu√°ntica. <br/>
              </p>
            </li>
            <li>
              <p align = "justify">
                 <strong> <i> 1913 </i> </strong> ‚û°Ô∏è Niels Bohr desarroll√≥ un modelo at√≥mico en donde postulaba que los electrones se mov√≠an en niveles espec√≠ficos y cuantificados de energ√≠a. Explica el por qu√© los √°tomos, en longitudes de onda espec√≠ficas absorben y emiten luz (Fotones con cantidades precisas de energ√≠a). <br/>
              </p>
            </li>
            <li>
              <p align = "justify">
                <strong> <i> 1925-1926 </i> </strong> ‚û°Ô∏è La mec√°nica matricial fue desarrollada por Werner Heisenberg, la mec√°nica ondulatoria formulada por Erwin Schr√∂dinger. Por medio de estos marcos matem√°ticos se estableci√≥ la mec√°nica cu√°ntica moderna, que establece que las part√≠culas est√°n en una dualidad de <i>onda-part√≠cula</i>, siguiendo el principio de <strong>incertidumbre</strong> y sentando las bases para la computaci√≥n cu√°ntica.
              </p>
            </li>
          </ul>
        </li>
        <li>
          <strong> 1930 - 1940 </strong>
          <ul>
            <li>
              <strong> <i> 1935 </i> </strong> ‚û°Ô∏è Einstein, Podolsky y Rosen publicaron un experimento mental en el que se destac√≥ el fen√≥meno de <strong>entrelazamiento cu√°ntico</strong>, recurso que se volvi√≥ fundamental en la computaci√≥ cu√°ntica. <br/>
            </li>
            <li>
              <strong> <i> 1939 </i> </strong> ‚û°Ô∏è Isidor Rabi mostr√≥ c√≥mo pueden cambiar los estados cu√°nticos de un n√∫cleo at√≥mico mediante ondas de radio por medio de la Resonancia Magn√©tica Nuclear. Esta t√©cnica fu√© la primera en poder controlar los estados cu√°nticos mediante radiaci√≥n electromagn√©tica, estableciendo los principios que evolucionaron en m√©todos capaces de manipular los qubits empleados en las computadoras cu√°nticas. <br/>
            </li>
          </ul>
        </li>
        <li>
          <strong> 1950 - 1970 </strong>
        </li>
        <ul>
          <li>
            <strong> <i> 1952 </i> </strong> ‚û°Ô∏è F√©lix Bloch y Edward Mills Purcell desarrollaron m√©todos precisos que permitieron a los cient√≠ficos observar precisamente las propiedades cu√°nticas de los √°tomos. Esto permiti√≥ establecer herramientas experimentales esenciales para el estudio y manipulaci√≥n de los sistemas cu√°nticos. <br/>
          </li>
          <li>
            <strong> <i> 1965 </i> </strong> ‚û°Ô∏è El teorema de Bell proporcion√≥ el marco para eventuales experimentos que confirmar√≠an la naturaleza no local del entrelazamiento y cuestionar√≠an nuestra comprensi√≥n fundamental de la realidad. <br/>
          </li>
          <li>
            <strong> <i> 1972 </i> </strong> ‚û°Ô∏è Alain Aspect, a inicios de los a√±os 80, realiz√≥ experimentos que confirmaron el entrelazamiento cu√°ntico, validando la <i>acci√≥n fantasmal a distancia</i> propuesta por la mec√°nica cu√°ntica. Sus hallazgos sentaron bases fundamentales para el desarrollo de la computaci√≥n cu√°ntica. <br/>
          </li>
        </ul>
        <li>
          <strong> 1980 - 1990 </strong>
        </li>
        <ul>
          <li>
            <strong> <i> 1981 </i> </strong> ‚û°Ô∏èRichard Feynman propuso que solo las computadoras cu√°nticas pod√≠an simular eficazmente sistemas cu√°nticos, planteando que resolver√≠an ciertos problemas mucho m√°s r√°pido que las cl√°sicas y estableciendo las bases te√≥ricas de la computaci√≥n cu√°ntica.
          </li>
          <li>
            <strong> <i> 1983 </i> </strong> ‚û°Ô∏è Alain Aspect confirm√≥ experimentalmente las violaciones de la desigualdad de Bell, demostrando de forma definitiva la realidad del entrelazamiento cu√°ntico y consolidando su papel como base para la computaci√≥n cu√°ntica.
          </li>
          <li>
            <strong> <i> 1985 </i> </strong> ‚û°Ô∏è David Deutsch formul√≥ el primer modelo te√≥rico de una computadora cu√°ntica universal, mostrando que las puertas cu√°nticas pod√≠an realizar cualquier c√°lculo cu√°ntico. Con ello extendi√≥ la computaci√≥n universal al √°mbito cu√°ntico y plante√≥ la posibilidad de resolver problemas imposibles para las computadoras cl√°sicas.
          </li>
          <li>
            <strong> <i> 1994 </i> </strong> ‚û°Ô∏è Peter Shor cre√≥ un algoritmo de factorizaci√≥n cu√°ntica que resolv√≠a grandes n√∫meros mucho m√°s r√°pido que los m√©todos cl√°sicos, demostrando la ventaja pr√°ctica de la computaci√≥n cu√°ntica y generando gran impacto en la criptograf√≠a y en la inversi√≥n en este campo.
          </li>
          <li>
            <strong> <i> 1995 </i> </strong> ‚û°Ô∏è El NIST demostr√≥ experimentalmente la primera puerta cu√°ntica controlada-NOT (CNOT), validando la posibilidad f√≠sica de operaciones b√°sicas entre c√∫bits y marcando el paso de la teor√≠a a la implementaci√≥n pr√°ctica de circuitos cu√°nticos.
          </li>
        </ul>
        <li>
          <strong> 2000 - Presente </strong>
        </li>
        <ul>
          <li>
            <strong> <i> 2001 </i> </strong> ‚û°Ô∏è Georges-Olivier Reymond y otros cient√≠ficos demostraron el uso de pinzas √≥pticas para atrapar √°tomos neutros individuales, logrando un control cu√°ntico preciso part√≠cula por part√≠cula. Este avance abri√≥ una nueva plataforma para el procesamiento de informaci√≥n cu√°ntica y dio origen a la tecnolog√≠a de Pasqal.
          </li>
          <li>
             <strong> <i> 2011 </i> </strong> ‚û°Ô∏è D-Wave One (128 qubits) se convierte en la primera computadora cu√°ntica disponible comercialmente
          </li>
          <li>
            <strong> <i> 2016 </i> </strong> ‚û°Ô∏è IBM ofrece acceso p√∫blico a computaci√≥n cu√°ntica v√≠a su plataforma en la nube (IBM Quantum Experience), democratizando el acceso a hardware cu√°ntico experimental.
          </li>
          <li>
            <strong> <i> 2016 </i> </strong> ‚û°Ô∏è 2019 ‚Äì Google, en colaboraci√≥n con NASA, anuncia la consecuci√≥n de la supremac√≠a cu√°ntica con su procesador de 54 qubits, al ejecutar una tarea que afirmaban ser√≠a impracticable para computadoras cl√°sicas. IBM refut√≥ parte de esta afirmaci√≥n, generando debate cient√≠fico.
          </li>
          <li>
            <strong> <i> 2018-2025 </i> </strong> ‚û°Ô∏è Esta fase se conoce como la era NISQ (Noisy Intermediate-Scale Quantum), caracterizada por dispositivos con hasta ~1000 qubits, aunque a√∫n sin correcci√≥n de errores completa. John Preskill acu√±a el t√©rmino en 2018, y en 2023 se supera la barrera de los 1,000 qubits f√≠sicos (Atom Computing, 1,180 qubits)
          </li>
        </ul>
      </ul>
    </p>

    
  - ### Ventajas y desventajas
<p align = "center" >

| **Ventajas**                                                                 | **Desventajas**                                                                 |
|------------------------------------------------------------------------------|---------------------------------------------------------------------------------|
| üöÄ Velocidad y eficiencia en ciertos problemas: resoluci√≥n exponencialmente m√°s r√°pida que en computadores cl√°sicos. | ‚ö†Ô∏è Fragilidad de los c√∫bits: muy sensibles al ruido y la decoherencia.           |
| üß™ Simulaci√≥n precisa de sistemas cu√°nticos: mol√©culas, materiales y reacciones qu√≠micas. | ‚ùÑÔ∏è Necesidad de condiciones extremas: refrigeraci√≥n casi al cero absoluto.      |
| üîé Optimizaci√≥n avanzada en log√≠stica, finanzas, energ√≠a y telecomunicaciones. | üìâ Escalabilidad limitada: actualmente solo decenas o cientos de c√∫bits.        |
| üîê Criptograf√≠a cu√°ntica: desarrollo de comunicaciones ultra seguras (QKD).   | üí∞ Altos costos y complejidad t√©cnica en infraestructura y mantenimiento.       |
| üåê Posibilidad de resolver problemas inalcanzables para supercomputadores cl√°sicos. | üîì Riesgo para la seguridad actual: amenaza a los sistemas criptogr√°ficos cl√°sicos (RSA, ECC). |
|                                                                              | üß™ Madurez tecnol√≥gica insuficiente: a√∫n en fase experimental con aplicaciones limitadas. |

</p>

  - ### Conceptos clave
    <ul>
      <li>
        <ins> <i> Superposici√≥n </i> </ins>
        <p align = "justify">
          Habla de la capacidad de una particula de estar en m√°s de un estado al mismo tiempo. <br/>
          ü™ô Imaginemos una moneda lanzada al aire: mientras est√° girando, no es solo cara o sello, sino una mezcla de ambos. Cuando cae al piso (cuando se mide), se convierte en un resultado concreto.
        </p>
      </li>
      <li>
         <ins> <i> Entrelazamiento </i> </ins>
        <p align = "justify">
          Establece que, sin importar la distancia, dos part√≠culas cu√°nticas pueden conectarse de tal forma que lo que le sucede a una, instant√°neamente afecta a la otra. <br/>
          üõ£Ô∏è Si entrelazamos dos monedas cu√°nticas y una resulta "cara", autom√°ticamente la otra ser√° "sello", incluso si est√°n separadas por kil√≥metros.
        </p>
      </li>
      <li>
         <ins> <i> Interferencia cu√°ntica </i> </ins>
        <p align = "justify">
          Al estar las part√≠culas en el estado de superposici√≥n, los posibles estados pueden sumarse o anularse, esto permite crear algoritmos que favorezcan respuestas o resultados correctos. <br/>
          üåä Pensemos en dos olas de agua: si coinciden, se refuerzan (interferencia constructiva); si est√°n opuestas, se cancelan (interferencia destructiva).
        </p>
      </li>
      <li>
         <ins> <i> Medici√≥n probabil√≠stica </i> </ins>
        <p align = "justify">
          Al tomar la medici√≥n de un qubit en estado de superposici√≥n, su medici√≥n no es concreta sino se determina por probabilidad. Esto explica el por qu√© es necesario repetir muchas veces los algoritmos cu√°nticos para obtener un resultado confiable. <br/>
          üìà un c√∫bit puede estar en 70% de probabilidad de ser 0 y 30% de ser 1. Al medirlo, el resultado ser√° 0 la mayor√≠a de veces, pero a veces ser√° 1.
        </p>
      </li>
      <li>
         <ins> <i> Desaf√≠o de decoherencia </i> </ins>
        <p>
          Sucede cuando un qubit pierde su estado cu√°ntico debido a interacciones con el ambiente, ya sea ruido, calor o radiaci√≥n. <br/>
          ‚ÅâÔ∏è Es como si la moneda en el aire fuera golpeada por el viento antes de caer: ya no refleja la verdadera probabilidad, sino un error.
        </p>
      </li>
      <li>
         <ins> <i> Tipos de comunicaci√≥n cu√°ntica </i> </ins>
        <ul>
          <li>
            <p align = "justify">
              <ins> Distribuci√≥n cu√°ntica de claves </ins>: Esta distribuci√≥n usa entrelazamiento para generar claves criptogr√°ficas imposibles de detectar.
            </p>
          </li>
          <li>
            <p align = "justify">
              <ins> Teletransportaci√≥n cu√°ntica </ins>: transmite el estado cu√°ntico de una part√≠cula a otra distante, usando entrelazamiento, aunque la part√≠cula en s√≠ no viaja.
            </p>
          </li>
          <li>
            <p align = "justify">
              <ins> Redes cu√°ntica </ins>: Es la idea de un ‚ÄúInternet cu√°ntico‚Äù basado en c√∫bits entrelazados.
            </p>
          </li>
        </ul>
        üèõÔ∏è La Universidad de Delft, en Pa√≠ses Bajos, logr√≥ en 2022 transmitir informaci√≥n cu√°ntica entre tres nodos distintos usando entrelazamiento.
      </li>
      <li>
         <ins> <i> Compuertas cu√°nticas </i> </ins>
        <p align = "justify">
          An√°logas a las compuertas l√≥gicas cl√°sicas, las compuertas cu√°nticas manipulan los qubits seg√∫n un algoritmo o circuito. <br/>
          - <strong> X gate <i>(NOT cu√°ntico)</i> </strong>: invierte el estado del qubit. <br/>
          - <strong> H gate <i>(Hadamard)</i> </strong>: Coloca a los qubits en estado de superposici√≥n. <br/>
          - <strong> CNOT <i>(Controlled-NOT)</i> </strong>: genera entrelazamiento, cambia el segundo c√∫bit solo si el primero es 1. <br/>
        </p>
        ‚öõÔ∏è Si tenemos dos c√∫bits: El primero = 1, El segundo = 0. Despu√©s de pasar por una CNOT ‚û°Ô∏è el segundo se convierte en 1.
      </li>
    </ul>
## 2. Computador Neurom√≥rfico
  
  <p align = "justify">
    Un computador neurom√≥rfico (tambi√©n llamado ingenier√≠a neurom√≥rfica) es un sistema de hardware y software dise√±ado para imitar el funcionamiento del cerebro humano. Integra elementos inspirados en neuronas y sinapsis reales, y procesa informaci√≥n de forma distribuida, paralela y altamente eficiente. <br/>
    Este enfoque busca superar limitaciones de la arquitectura tradicional de von Neumann, especialmente en t√©rminos de consumo de energ√≠a y latencia.
  </p>

  - ### Arquitectura de un computador neurom√≥rfico
    <ul>
      <li>
        <strong> Entrada y codificaci√≥n sensorial </strong>
        <p align = "justify">
          Son m√≥dulos que toman se√±ales externas como imagen, audio, etc, y las convierten en <i> eventos (o spikes) </i> en lugar de cuadros continuos de datos. Esto reduce datos y latencia, solo emite algo cuando cambia la escena. Por ejemplo, c√°maras de eventos (DVS) generan un evento por pixel cuando detectan un cambio de luminancia; si nada cambia, no emiten casi nada. <br/>
        </p>
      </li>
      <li>
        <strong> N√∫cleos neurosin√°pticos </strong>
        <p align = "justify">
          Agrupa las neuronas y sus sinapsis. Cada n√∫cleo recibe spikes en axones (entradas), los pondera con una matriz sin√°ptica y actualiza el estado de cada neurona; cuando una neurona supera umbral, emite un spike a la red.
        </p>
      </li>
      <li>
        <strong> Motor de plasticidad </strong>
        <p align = "justify">
          Es la l√≥gica cerca de las sinapsis que actualiza pesos con reglas locales (por ejemplo, STDP, refuerzo, aprendizaje hebbiano). Permite aprendizaje on-chip sin ir a CPU externa, manteniendo el procesamiento en memoria y event-driven
        </p>
      </li>
      <li>
        <strong> Memoria sin√°ptica y representaci√≥n de pesos </strong>
        <p lign = "justify">
          Es d√≥nde viven los pesos y metadatos (retrasos, ‚Äútipo de ax√≥n‚Äù, etc.). Suele ser SRAM distribuida por n√∫cleo; en plataformas anal√≥gicas/memristivas puede ser NVM.d√≥nde viven los pesos y metadatos (retrasos, ‚Äútipo de ax√≥n‚Äù, etc.). Suele ser SRAM distribuida por n√∫cleo; en plataformas anal√≥gicas/memristivas puede ser NVM.Habilita el c√≥mputo en memoria: el acceso a los pesos ocurre localmente para cada spike, sin tr√°fico a DRAM externo.
        </p>
      </li>
      <li>
        <strong> Red de interconexi√≥n </strong>
        <p align = "justify">
          Es la ‚Äúmalla‚Äù que transporta spikes como paquetes ligeros con la direcci√≥n del emisor o del destino: Address-Event Representation (AER). Enruta spikes de forma as√≠ncrona y multicast (un spike se copia a muchos destinos), escalando a redes grandes con baja latencia.
        </p>
      </li>
      <li>
        <strong> Cl√∫ster neurom√≥rfico </strong>
        <p align = "justify">
          Son topolog√≠as multi-chip/multi-nodo con routers de alto fan-out y encaminamiento tolerante a fallos. Permite simular/controlar redes neuronales masivas en tiempo biol√≥gico.
        </p>
      </li>
      <li>
        <strong> Temporizaci√≥n y ejecuci√≥n as√≠ncrona </strong>
        <p align = "justify">
          Muchos dise√±os evitan un reloj global; las actualizaciones ocurren al arribo de eventos o por clocks locales. Esto reduce consumo (no hay conmutaci√≥n si no hay eventos) y elimina cuellos de botella de sincronizaci√≥n global.
        </p>
      </li>
      <li>
        <strong> Control y monitorizaci√≥n </strong>
        <p align = "justify">
          Son microcontroladores/cores de servicio que cargan configuraciones, inician experimentos, colectan m√©tricas y comunican con el host. Esto orquesta el sistema sin intervenir en el tr√°fico fino de spikes.
        </p>
      </li>
      <li>
        <strong> Software y mapeo </strong>
        <p align = "justify">
          Son toolchains para compilar/redesplegar SNNs a n√∫cleos (particionado, asignaci√≥n de neuronas/sinapsis, ruteo). Traduce modelos (por ejemplo, PyNN/Loihi API) a configuraciones de hardware cumpliendo l√≠mites de fan-in/fan-out, memoria y latencias.
        </p>
      </li>
    </ul>

    Es decir que: Un sensor/event-encoder convierte se√±ales en spikes. ‚ñ∂Ô∏è Los spikes entran a un n√∫cleo; la crossbar/tabla sin√°ptica suma entradas, actualiza neuronas y emite nuevos spikes. ‚ñ∂Ô∏è La NoC/AER reenv√≠a esos spikes (multicast) a otros n√∫cleos/chips. ‚ñ∂Ô∏è Si hay plasticidad, el motor local ajusta pesos en tiempo real. ‚ñ∂Ô∏è Los cores de control orquestan, miden y comunican con el host.
    
  - ### Ventajas y Desventajas
    <p align = "center">

| **Ventajas**                                                                 | **Desventajas**                                                                 |
|------------------------------------------------------------------------------|---------------------------------------------------------------------------------|
| ‚ö° **Alta eficiencia energ√©tica**: consumen mucho menos que los computadores tradicionales para tareas de IA. | üõ†Ô∏è **Tecnolog√≠a inmadura**: a√∫n en fase de investigaci√≥n y desarrollo, con aplicaciones limitadas. |
| üß† **Procesamiento paralelo masivo**: inspirado en el cerebro humano, permite gran capacidad de c√≥mputo en tareas cognitivas. | üí∞ **Alto costo de desarrollo**: fabricaci√≥n y dise√±o de chips neurom√≥rficos es costosa. |
| üîé **Optimizaci√≥n en IA**: muy eficientes en reconocimiento de patrones, visi√≥n artificial, procesamiento sensorial y rob√≥tica. | üîå **Dificultad de integraci√≥n**: falta de compatibilidad con arquitecturas cl√°sicas de Von Neumann. |
| üåê **Escalabilidad biol√≥gica**: permite crear redes que imitan al cerebro humano, facilitando avances en IA general. | üìâ **Limitaciones en software**: escasez de lenguajes y herramientas de programaci√≥n adaptadas. |
| üîí **Robustez en condiciones adversas**: algunos dise√±os toleran fallos y ruido en el procesamiento. | ‚ùì **Aplicaciones poco claras a gran escala**: su utilidad pr√°ctica frente a supercomputadores cl√°sicos a√∫n est√° en evaluaci√≥n. |
  
    
  </p>
    
  - ### Tipos de computaci√≥n neurom√≥rfica
    <ul>
      <li>
        <strong> Computaci√≥n Neurom√≥rfica Digital </strong>
        <p align = "justify">
          Es hardware construido en tecnolog√≠a CMOS ‚Äúcl√°sica‚Äù (digital) pero organizado como redes de neuronas que disparan picos (spikes). En lugar de hacer grandes multiplicaciones de matrices (como una GPU), estas m√°quinas procesan eventos: cada pico es un mensaje diminuto que viaja por una red-on-chip hacia sus sinapsis destino. As√≠ se ahorra energ√≠a cuando no hay actividad y se imita la din√°mica temporal de los sistemas biol√≥gicos. Una revisi√≥n t√©cnica que enmarca el √°rea (y compara enfoques anal√≥gico vs. digital) es la de Indiveri & Liu (Proc. IEEE, 2015). Se compone por: <br/>
          <ul>
            <li>
              <i> Neuronas y sinapsis digitales </i>
            </li>
            <li>
              <i> Memoria local cercana al c√≥mputo </i>
            </li>
            <li>
              <i> Comunicaci√≥n NoC / AER </i>
            </li>
          </ul>
        </p>
      </li>
      <li>
        <strong> Computaci√≥n neurom√≥rfica anal√≥gica </strong>
        <p align = "justify">
          En lugar de representar los estados neuronales como n√∫meros discretos en hardware digital (como en TrueNorth o Loihi), aqu√≠ se usan se√±ales anal√≥gicas (voltajes, corrientes) y elementos f√≠sicos que imitan directamente la din√°mica de membranas y sinapsis biol√≥gicas. Puede ser anal√≥gica pura: todo el c√°lculo (suma de corrientes, integraci√≥n de voltajes) ocurre con leyes f√≠sicas continuas (Ohm, Kirchhoff, capacitancias). o puede ser mixta: se usan bloques anal√≥gicos para la din√°mica neuronal/sin√°ptica, pero control digital para configuraci√≥n, comunicaci√≥n o calibraci√≥n. Para su arquitectura se pueden comprender cuatro bloques de funcionamiento: <br/>
          <ul>
            <li>
              <i> Neuronas anal√≥gicas </i>
              <p align = "justify">
                Se implementan con transistores y condensadores que replican el modelo LIF (Leaky Integrate-and-Fire). Un capacitor acumula carga (potencial de membrana); cuando supera un umbral, un comparador genera un ‚Äúspike‚Äù.
              </p>
            </li>
            <li>
              <i> Sinapsis anal√≥gica </i>
              <p align = "justify">
                Donde Resistores, transistores subumbral o memristores representan pesos sin√°pticos. La corriente que fluye depende del peso, lo que implementa la multiplicaci√≥n peso √ó spike de forma natural.
              </p>
            </li>
            <li>
              <i> Plasticidad local </i>
              <p align = "justify">
                STDP (Spike-Timing Dependent Plasticity) puede implementarse directamente en hardware: el solapamiento temporal de se√±ales cambia la conductancia de un memristor o transistor.
              </p>
            </li>
            <li>
              <i> Comunicaci√≥n </i>
              <p align = "justify">
                Muchos chips usan AER (Address-Event Representation), como en digital, pero el n√∫cleo neuronal es anal√≥gico. Otras implementaciones son completamente anal√≥gicas, con redes de voltajes acoplados.
              </p>
            </li>
          </ul>
        </p>
      Conviene cuando se requiere eficiencia extrema (nanowatts por sinapsis), En prototipos de sistemas aut√≥nomos de bajo consumo (robots insectoides, sensores inteligentes) y sirve para estudiar modelos biol√≥gicos realistas con plasticidad emergente.
      </li>
      <li>
        <strong> Computaci√≥n neurom√≥rfica H√≠brida </strong>
        <p>
          Este enfoque combina lo mejor de los dos mundos:Bloques digitales (para control, programaci√≥n, escalabilidad y comunicaci√≥n robusta), Bloques anal√≥gicos (para emular la din√°mica neuronal y sin√°ptica con alta eficiencia energ√©tica) y Algoritmos bioinspirados (modelos simplificados del cerebro como el aprendizaje local, redes oscilatorias, plasticidad, etc.). En este tipo, un chip h√≠brido suele dividirse en tres niveles:
          <ul>
            <li>
              Capa anal√≥gica (neuronal/sin√°ptica)
              <p align = "justify">
                Implementa la din√°mica del potencial de membrana y las sinapsis (p. ej., con condensadores, transistores en subumbral o memristores). Aqu√≠ ocurre el c√≥mputo f√≠sico (integraci√≥n, disparo, plasticidad local).
              </p>
            </li>
            <li>
              Capa digital (control y comunicaci√≥n)
              <p align = "justify">
                Controla la configuraci√≥n de par√°metros (umbrales, pesos, tiempos de aprendizaje). Maneja la comunicaci√≥n entre chips usando protocolos como AER (Address-Event Representation). Permite reprogramar redes sin necesidad de redise√±ar el hardware.
              </p>
            </li>
            <li>
              Software bioinspirado (modelos de red)
              <p align = "justify">
                Algoritmos que se acercan al comportamiento del cerebro, como aprendizaje Hebbiano, STDP, homeostasis. Traducci√≥n de redes de IA convencionales a redes spiking para aprovechar el hardware h√≠brido.
              </p>
            </li>
          </ul>
        </p>
      </li>
      <li>
        <strong> Computaci√≥n neurom√≥rfica con Dispositivos emergentes </strong>
        <p align = "justify">
          Este enfoque usa nuevos materiales y tecnolog√≠as de hardware diferentes al silicio tradicional, inspirados directamente en la forma en que funcionan las neuronas y sinapsis biol√≥gicas. En lugar de implementar neuronas y sinapsis solo con transistores CMOS cl√°sicos, se aprovechan dispositivos como:
          <ul>
            <li> 
              <i> Memristores </i> ‚û°Ô∏è Componentes que recuerdan la corriente pasada (sinapsis con memoria).
            </li>
            <li>
              <i> RRAM (Resistive RAM) </i> ‚û°Ô∏è Resistencias que cambian su valor seg√∫n el voltaje aplicado.
            </li>
            <li>
              <i> PCM (Phase-Change Memory) </i> ‚û°Ô∏è Materiales que cambian entre estados amorfo y cristalino (como una sinapsis pl√°stica).
            </li>
            <li>
              <i> Dispositivos spintr√≥nicos </i> ‚û°Ô∏è Usan el esp√≠n del electr√≥n, no solo su carga, para procesar.
            </li>
            <li>
              <i> Nanofot√≥nica </i> ‚û°Ô∏è Usa la luz para transmitir informaci√≥n como si fueran spikes neuronales.
            </li>
          </ul>
        </p>
      </li>
      <li>
        <strong> Computaci√≥n neurom√≥rfica Fot√≥nica </strong>
        <p align = "justify">
          La computaci√≥n neurom√≥rfica fot√≥nica utiliza luz (fotones) en lugar de electrones para procesar y transmitir informaci√≥n en sistemas que imitan al cerebro.
En vez de transistores o memristores, se emplean l√°seres, moduladores √≥pticos, gu√≠as de onda y detectores de luz para construir "neuronas" y "sinapsis" artificiales. Funciona con una se√±al de entrada (un pulso de luz entra en un modulador √≥ptico), luego ocurre un procesamiento neurom√≥rfico, aqu√≠ la intensidad, fase o polarizaci√≥n de la luz se modifica (imitando c√≥mo cambia la fuerza de una sinapsis), sigue una suma de se√±ales en donde m√∫ltiples se√±ales √≥pticas se combinan en un interfer√≥metro, tal como lo hacen las neuronas al integrar impulsos. Por √∫ltimo ocurre una activaci√≥n, es decir, un l√°ser o detector convierte el resultado en una se√±al de salida √≥ptica, lista para ser enviada a la siguiente "neurona".
        </p>
      </li>
    </ul>
  
# Referencias
1. [Sint√°xis de escritura y formato b√°sicos](https://docs.github.com/es/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax)
2. [Listas en HTML](https://www.mclibre.org/consultar/htmlcss/html/html-listas.html)
3. [¬øQu√© es la computaci√≥n cu√°ntica? IBM](https://www.ibm.com/es-es/topics/quantum-computing)
4. [¬øQu√© es la computaci√≥n cu√°ntica? AWS](https://aws.amazon.com/es/what-is/quantum-computing/)
5. [¬øC√≥mo es una computadora cu√°ntica? - La estructura f√≠sica de una computadora cu√°ntica](https://www.spinquanta.com/news-detail/what-does-a-quantum-computer-look-like-explain-key-parts20250116063551+)
6. [Quantum Computing History: Path to Pasqal](https://www.pasqal.com/quantum-computing-history-path-to-pasqal/#1900s)
7. [Quantum Computing: a Timeline](https://www.btq.com/blog/quantum-computing-a-timeline)
8. [History of Quantum computing](https://www.livescience.com/technology/computing/history-of-quantum-computing-key-moments-that-shaped-the-future-of-computing)
9. [¬øQu√© es la computaci√≥n neurom√≥rfica? IBM](https://www.ibm.com/es-es/think/topics/neuromorphic-computing)
10. [Overview of the SpiNNaker system Architecture](https://www.researchgate.net/publication/260585643_Overview_of_the_SpiNNaker_System_Architecture)
11. 
